package main

import (
	"context"
	"fmt"
	"runtime"
	"time"

	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/mongo/options"
)

// read_v5.go - Ä°YÄ°LEÅTÄ°RME 5: Aggregation Pipeline Optimizasyonu
// Bu versiyon, MongoDB aggregation pipeline kullanÄ±r
// Aggregation pipeline, MongoDB'de veri iÅŸleme iÃ§in en gÃ¼Ã§lÃ¼ yÃ¶ntemdir
//
// AvantajlarÄ±:
// 1. Veri iÅŸleme MongoDB tarafÄ±nda yapÄ±lÄ±r (network trafiÄŸi azalÄ±r)
// 2. Pipeline stage'leri optimize edilebilir
// 3. $match stage'i index kullanabilir
// 4. $project stage'i sadece gerekli alanlarÄ± getirir
// 5. MongoDB'nin built-in optimizasyonlarÄ±ndan faydalanÄ±r
func main() {
	// Logger oluÅŸtur
	logger, err := NewLogger("read_v5_results.txt")
	if err != nil {
		fmt.Printf("Logger oluÅŸturulamadÄ±: %v\n", err)
		return
	}
	defer logger.Close()
	
	logger.WriteHeader("read_v5 - Ä°YÄ°LEÅTÄ°RME 5 (Aggregation Pipeline)")
	
	col := GetMongo()
	ctx := context.Background()

	// Aggregation pipeline oluÅŸtur
	// Pipeline stage'leri sÄ±rayla Ã§alÄ±ÅŸÄ±r:
	// 1. $match: Filtreleme - index kullanabilir (status="PAID" iÃ§in index var)
	// 2. $project: Sadece gerekli alanlarÄ± getir
	// 
	// Aggregation pipeline'Ä±n avantajlarÄ±:
	// - $match stage'i index kullanabilir (IXSCAN) - Ã§ok hÄ±zlÄ±!
	// - $project stage'i sadece gerekli alanlarÄ± getirir - network trafiÄŸi azalÄ±r
	// - Veri iÅŸleme MongoDB tarafÄ±nda yapÄ±lÄ±r - Go tarafÄ±nda daha az iÅŸlem
	pipeline := []bson.M{
		{
			"$match": bson.M{
				"status": "PAID", // Filtreleme - index kullanÄ±labilir
			},
		},
		{
			"$project": bson.M{
				"userId": 1,  // Sadece bu alanlarÄ± getir
				"status": 1,
				"_id":    0,  // _id'yi getirme
			},
		},
	}

	// Explain iÃ§in aggregation explain komutu
	// $match stage'i index kullanabilir, bu Ã§ok Ã¶nemli!
	logger.Println("ğŸ” Aggregation pipeline analizi yapÄ±lÄ±yor (explain with $match)...")
	
	// Aggregation explain komutu
	var explainResult map[string]interface{}
	// err zaten tanÄ±mlÄ± (logger oluÅŸtururken), bu yÃ¼zden := yerine = kullanÄ±yoruz
	err = col.Database().RunCommand(ctx, bson.D{
		{Key: "explain", Value: bson.D{
			{Key: "aggregate", Value: col.Name()},
			{Key: "pipeline", Value: pipeline},
			{Key: "cursor", Value: bson.M{"batchSize": 1000}},
		}},
		{Key: "verbosity", Value: "executionStats"},
	}).Decode(&explainResult)
	
	if err != nil {
		logger.Printf("âš ï¸  Explain hatasÄ±: %v\n", err)
	} else {
		PrintExplainResults(explainResult, "read_v5 (Aggregation Pipeline)", logger)
	}

	// Performans Ã¶lÃ§Ã¼mÃ¼ baÅŸlat
	start := time.Now()
	
	var memBefore runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&memBefore)

	// Aggregation pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
	// Aggregation, MongoDB'de veri iÅŸleme iÃ§in en gÃ¼Ã§lÃ¼ yÃ¶ntemdir
	// Veri iÅŸleme MongoDB tarafÄ±nda yapÄ±lÄ±r, sadece sonuÃ§lar gelir
	cursor, err := col.Aggregate(ctx, pipeline, options.Aggregate().SetBatchSize(1000))
	if err != nil {
		panic(err)
	}
	defer cursor.Close(ctx)

	// SonuÃ§larÄ± oku
	recordCount := 0
	for cursor.Next(ctx) {
		var result bson.M
		if err := cursor.Decode(&result); err != nil {
			panic(err)
		}
		
		// Burada sadece iÅŸlenmiÅŸ veri var (MongoDB tarafÄ±nda iÅŸlendi)
		_ = result
		recordCount++
		
		if recordCount%100000 == 0 {
			logger.Printf("  ğŸ“Š Ä°ÅŸlenen kayÄ±t: %d\n", recordCount)
		}
	}

	if err := cursor.Err(); err != nil {
		panic(err)
	}

	var memAfter runtime.MemStats
	runtime.ReadMemStats(&memAfter)
	memoryUsed := int64(memAfter.Alloc - memBefore.Alloc)

	duration := time.Since(start)

	logger.Printf("\nâœ… Ä°YÄ°LEÅTÄ°RME 5 SONUÃ‡LARI (Aggregation Pipeline):\n")
	logger.Printf("ğŸ“¦ Okunan KayÄ±t: %d\n", recordCount)
	logger.Printf("â±ï¸  SÃ¼re: %v\n", duration)
	logger.Printf("ğŸ’¾ Bellek KullanÄ±mÄ±: %.2f MB\n", float64(memoryUsed)/(1024*1024))
	logger.Printf("ğŸš€ Aggregation pipeline sayesinde MongoDB tarafÄ±nda iÅŸleme yapÄ±ldÄ±!\n")
	
	if explainResult != nil {
		// Aggregation explain sonuÃ§larÄ± biraz farklÄ± yapÄ±da olabilir
		if stages, ok := explainResult["stages"].([]interface{}); ok {
			logger.Println("\nğŸ“‹ Pipeline Stage'leri:")
			for i, stage := range stages {
				if stageMap, ok := stage.(map[string]interface{}); ok {
					if stageName, ok := stageMap["stage"].(string); ok {
						logger.Printf("  Stage %d: %s\n", i+1, stageName)
					}
				}
			}
		}
		
		// Execution stats varsa gÃ¶ster
		if execStats, ok := explainResult["executionStats"].(map[string]interface{}); ok {
			metrics := QueryMetrics{
				Duration:    duration,
				RecordsRead: recordCount,
				MemoryUsed:  memoryUsed,
			}
			
			if execTime, ok := execStats["executionTimeMillis"].(int64); ok {
				metrics.ExecutionStats = &ExecutionStats{
					ExecutionTimeMillis: execTime,
				}
			}
			if totalDocs, ok := execStats["totalDocsExamined"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.TotalDocsExamined = totalDocs
			}
			if totalKeys, ok := execStats["totalKeysExamined"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.TotalKeysExamined = totalKeys
			}
			if nReturned, ok := execStats["nReturned"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.NReturned = nReturned
			}
			
			PrintMetrics(metrics, "read_v5", logger)
		}
	}
	
	logger.Println("\nâœ… Test tamamlandÄ±! SonuÃ§lar 'read_v5_results.txt' dosyasÄ±na kaydedildi.")
}

