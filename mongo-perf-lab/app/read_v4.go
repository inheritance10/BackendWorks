package main

import (
	"context"
	"fmt"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/mongo/options"
)

// read_v4.go - Ä°YÄ°LEÅTÄ°RME 4: Paralel Aggregation Pipeline
// Bu versiyon, aggregation pipeline'Ä± paralel olarak Ã§alÄ±ÅŸtÄ±rÄ±r
// Her worker ayrÄ± bir aggregation pipeline Ã§alÄ±ÅŸtÄ±rÄ±r
//
// AvantajlarÄ±:
// 1. Aggregation pipeline kullanÄ±mÄ± (MongoDB tarafÄ±nda iÅŸleme)
// 2. $match stage'i index kullanabilir
// 3. Paralel iÅŸleme sayesinde throughput artar
// 4. CPU ve network'Ã¼ daha iyi kullanÄ±r
//
// Dikkat:
// - MongoDB connection pool size'Ä± yeterli olmalÄ±
// - Ã‡ok fazla goroutine memory kullanÄ±mÄ±nÄ± artÄ±rabilir
func main() {
	// Logger oluÅŸtur
	logger, err := NewLogger("read_v4_results.txt")
	if err != nil {
		fmt.Printf("Logger oluÅŸturulamadÄ±: %v\n", err)
		return
	}
	defer logger.Close()
	
	logger.WriteHeader("read_v4 - Ä°YÄ°LEÅTÄ°RME 4 (Parallel Reading)")
	
	col := GetMongo()
	ctx := context.Background()

	// Aggregation pipeline oluÅŸtur
	// Pipeline stage'leri sÄ±rayla Ã§alÄ±ÅŸÄ±r:
	// 1. $match: Filtreleme - index kullanabilir
	// 2. $project: Sadece gerekli alanlarÄ± getir
	pipeline := []bson.M{
		{
			"$match": bson.M{
				"status": "PAID", // Filtreleme - index kullanÄ±labilir
			},
		},
		{
			"$project": bson.M{
				"userId": 1,  // Sadece bu alanlarÄ± getir
				"status": 1,
				"_id":    0,  // _id'yi getirme
			},
		},
	}

	// Ã–nce eÅŸleÅŸen kayÄ±t sayÄ±sÄ±nÄ± bul
	totalCount, err := col.CountDocuments(ctx, bson.M{"status": "PAID"})
	if err != nil {
		panic(err)
	}
	logger.Printf("ğŸ“Š EÅŸleÅŸen kayÄ±t sayÄ±sÄ± (status='PAID'): %d\n", totalCount)

	// Paralel okuma iÃ§in ayarlar
	numWorkers := 10        // KaÃ§ goroutine paralel Ã§alÄ±ÅŸacak
	chunkSize := int64(100000) // Her chunk'ta kaÃ§ kayÄ±t olacak

	// Explain Ã§alÄ±ÅŸtÄ±r - Aggregation pipeline iÃ§in
	logger.Println("ğŸ” Aggregation pipeline analizi yapÄ±lÄ±yor...")
	var explainResult map[string]interface{}
	err = col.Database().RunCommand(ctx, bson.D{
		{Key: "explain", Value: bson.D{
			{Key: "aggregate", Value: col.Name()},
			{Key: "pipeline", Value: pipeline},
			{Key: "cursor", Value: bson.M{"batchSize": 1000}},
		}},
		{Key: "verbosity", Value: "executionStats"},
	}).Decode(&explainResult)
	
	if err != nil {
		logger.Printf("âš ï¸  Explain hatasÄ±: %v\n", err)
	} else {
		PrintExplainResults(explainResult, "read_v4 (Parallel Aggregation)", logger)
	}

	// Performans Ã¶lÃ§Ã¼mÃ¼ baÅŸlat
	start := time.Now()
	
	var memBefore runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&memBefore)

	// Paralel okuma iÃ§in channel ve wait group
	var wg sync.WaitGroup
	var totalRead int64 // Atomic counter for thread-safe counting

	// Her worker iÃ§in goroutine baÅŸlat
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			// Bu worker'Ä±n okuyacaÄŸÄ± chunk'Ä± hesapla
			skip := int64(workerID) * chunkSize
			
			// EÄŸer skip, toplam kayÄ±t sayÄ±sÄ±ndan bÃ¼yÃ¼kse, bu worker'a iÅŸ yok
			if skip >= totalCount {
				return
			}

			// Bu chunk iÃ§in aggregation pipeline oluÅŸtur
			// $match: Filtreleme (index kullanabilir)
			// $skip: skip kadar kayÄ±t atla
			// $limit: chunkSize kadar kayÄ±t getir
			// $project: Sadece gerekli alanlarÄ± getir
			chunkPipeline := []bson.M{
				{
					"$match": bson.M{
						"status": "PAID", // Filtreleme - index kullanÄ±labilir
					},
				},
				{
					"$skip": skip, // skip kadar kayÄ±t atla
				},
				{
					"$limit": chunkSize, // chunkSize kadar kayÄ±t getir
				},
				{
					"$project": bson.M{
						"userId": 1,
						"status": 1,
						"_id":    0,
					},
				},
			}

			// Aggregation pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
			cursor, err := col.Aggregate(ctx, chunkPipeline, options.Aggregate().SetBatchSize(1000))
			if err != nil {
				logger.Printf("âš ï¸  Worker %d hatasÄ±: %v\n", workerID, err)
				return
			}
			defer cursor.Close(ctx)

			// Bu chunk'Ä± oku
			localCount := 0
			for cursor.Next(ctx) {
				var result bson.M
				if err := cursor.Decode(&result); err != nil {
					logger.Printf("âš ï¸  Worker %d decode hatasÄ±: %v\n", workerID, err)
					continue
				}
				
				_ = result
				localCount++
			}

			if err := cursor.Err(); err != nil {
				logger.Printf("âš ï¸  Worker %d cursor hatasÄ±: %v\n", workerID, err)
			}

			// Toplam sayacÄ± gÃ¼ncelle (thread-safe)
			atomic.AddInt64(&totalRead, int64(localCount))
			
			logger.Printf("  âœ… Worker %d tamamlandÄ±: %d kayÄ±t okundu\n", workerID, localCount)
		}(i)
	}

	// TÃ¼m worker'larÄ±n bitmesini bekle
	wg.Wait()

	var memAfter runtime.MemStats
	runtime.ReadMemStats(&memAfter)
	memoryUsed := int64(memAfter.Alloc - memBefore.Alloc)

	duration := time.Since(start)

	logger.Printf("\nâœ… Ä°YÄ°LEÅTÄ°RME 4 SONUÃ‡LARI (Parallel Aggregation):\n")
	logger.Printf("ğŸ“¦ Okunan KayÄ±t: %d\n", totalRead)
	logger.Printf("â±ï¸  SÃ¼re: %v\n", duration)
	logger.Printf("ğŸ’¾ Bellek KullanÄ±mÄ±: %.2f MB\n", float64(memoryUsed)/(1024*1024))
	logger.Printf("ğŸš€ Paralel aggregation pipeline sayesinde daha hÄ±zlÄ±!\n")
	logger.Printf("ğŸ‘¥ Worker sayÄ±sÄ±: %d\n", numWorkers)
	logger.Printf("ğŸ“Š Her worker ayrÄ± aggregation pipeline Ã§alÄ±ÅŸtÄ±rdÄ± ($match + $project)\n")
	
	if explainResult != nil {
		if execStats, ok := explainResult["executionStats"].(map[string]interface{}); ok {
			metrics := QueryMetrics{
				Duration:    duration,
				RecordsRead: int(totalRead),
				MemoryUsed:  memoryUsed,
			}
			
			if execTime, ok := execStats["executionTimeMillis"].(int64); ok {
				metrics.ExecutionStats = &ExecutionStats{
					ExecutionTimeMillis: execTime,
				}
			}
			if totalDocs, ok := execStats["totalDocsExamined"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.TotalDocsExamined = totalDocs
			}
			if totalKeys, ok := execStats["totalKeysExamined"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.TotalKeysExamined = totalKeys
			}
			if nReturned, ok := execStats["nReturned"].(int64); ok {
				if metrics.ExecutionStats == nil {
					metrics.ExecutionStats = &ExecutionStats{}
				}
				metrics.ExecutionStats.NReturned = nReturned
			}
			
			PrintMetrics(metrics, "read_v4", logger)
		}
	}
	
	logger.Println("\nâœ… Test tamamlandÄ±! SonuÃ§lar 'read_v4_results.txt' dosyasÄ±na kaydedildi.")
}

